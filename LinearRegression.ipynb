{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import PolynomialFeatures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_diabetes()\n",
    "X = data['data']\n",
    "y = data['target']\n",
    "np.random.seed(32)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2 )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\\theta = (X^{T}X)^{-1}X^{T}y$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Derivative = 0 formula\n",
    "model1 = np.linalg.inv(X_train.T @ X_train) @ (X_train.T) @ y_train\n",
    "y_hat_1 = X_test @ model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn Implementation\n",
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat_2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Singular Value Decomposition\n",
    "U, S, VT= np.linalg.svd(X_train, full_matrices=False)\n",
    "model3 = VT.T @ np.linalg.inv(np.diag(S)) @ U.T @ y_train\n",
    "y_hat_3 = X_test @ model3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = np.arange(len(y_test))\n",
    "plt.plot(sno, y_test)\n",
    "plt.plot(sno, y_hat_1)\n",
    "plt.plot(sno, y_hat_2)\n",
    "# plt.plot(sno, y_hat_3) # gives same result as model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss \n",
    "mean_squared_error(y_test,y_hat_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sklearn implementation loss\n",
    "mean_squared_error(y_test,y_hat_2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Polynomial Regression \\\n",
    "We can improve the peroformance of Linear Regression by adding polynomials of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trans = PolynomialFeatures(degree = 2)\n",
    "X_train_with_pf = trans.fit_transform(X_train)\n",
    "X_test_with_pf = trans.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = np.linalg.inv(X_train_with_pf.T @ X_train_with_pf) @ (X_train_with_pf.T) @ y_train\n",
    "y_hat_1 = X_test_with_pf @ model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = LinearRegression()\n",
    "model2.fit(X_train, y_train)\n",
    "y_hat_2 = model2.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sno = np.arange(len(y_hat_1))\n",
    "plt.plot(sno,y_test)\n",
    "plt.plot(sno, y_hat_1)\n",
    "plt.plot(sno, y_hat_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss \n",
    "mean_squared_error(y_test,y_hat_1)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see by adding polynomial features, the mean squared error reduced by a factor of 8! and gave a much better model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "More Basis Functions \\\n",
    "Similar to ading polynomials as features, we can add features which are function of given features"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Chebyshev Polynomials"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_{0}(x) = 1$\\\n",
    "$T_{1}(x) = x$\\\n",
    "$T_{n+1}(x) = 2xT_{n}(x) - T_{n-1}(x)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chebyshev Polynomials\n",
    "def chebyshev_polynomial(x,degree):\n",
    "    n = degree\n",
    "    if degree == 0 :\n",
    "        return 1\n",
    "    elif degree == 1:\n",
    "        return x\n",
    "    else :\n",
    "        return (2*x)*chebyshev_polynomial(x,n-1) - chebyshev_polynomial(x,n-2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Legendre Polynomial"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P_{0}(x) = 1$\\\n",
    "$P_{1}(x) = x$\\\n",
    "$(n+1)P_{n+1}(x) = (2n+1)P_{n}(x) - P_{n-1}(x)$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Legendre Polynomial\n",
    "def legendre_polynomial(x, degree):\n",
    "    n = degree\n",
    "    if degree == 0 :\n",
    "        return 1\n",
    "    elif degree == 1:\n",
    "        return x\n",
    "    else :\n",
    "        return ((1/n)*((2*n-1)*legendre_polynomial(x,n-1) - legendre_polynomial(x,n-2)))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bernstein Basis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$B_{n,i}(x) = {n\\choose i} (1-x)^{n-i}x^{i} $"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1 (v3.11.1:a7a450f84a, Dec  6 2022, 15:24:06) [Clang 13.0.0 (clang-1300.0.29.30)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
